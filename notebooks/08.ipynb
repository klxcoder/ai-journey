{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fcc574",
   "metadata": {},
   "source": [
    "# PyTorch basics\n",
    "- Since PyTorch is getting popular\n",
    "- We'll learn PyTorch basics in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ab436",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f861325",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d023a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ecab5",
   "metadata": {},
   "source": [
    "# Examples\n",
    "- scalar\n",
    "- vector\n",
    "- matrix\n",
    "- tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea52d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1400)\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14)\n",
    "print(scalar) # tensor(3.1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da70a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6a5a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d26581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]]\n",
    "])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f1fe0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fa80e",
   "metadata": {},
   "source": [
    "# numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53041a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "torch_tensor = torch.from_numpy(np_arr)\n",
    "print(np_arr)\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0346d0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c104f45",
   "metadata": {},
   "source": [
    "# tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ad65f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]]\n",
    "])\n",
    "np_arr = tensor.numpy()\n",
    "print(np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982209d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4837d7",
   "metadata": {},
   "source": [
    "# Fully Connected Layer (Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bad29cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "tensor([[0.3442, 0.1684, 0.5057, 0.0043]])\n",
      "tensor([[-0.4281,  0.1108]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = torch.nn.Linear(in_features=4, out_features=2)\n",
    "print(layer)\n",
    "x = torch.rand(1, 4)  # input batch with 4 features\n",
    "print(x)\n",
    "out = layer(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a888b47",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c9baf",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2149a2c",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9834f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1108]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "out_relu = relu(out)\n",
    "print(out_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2afeb70",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddca5040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3946, 0.5277]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "out_sigmoid = sigmoid(out)\n",
    "print(out_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2133faf",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed005064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4037,  0.1103]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tanh = torch.nn.Tanh()\n",
    "out_tanh = tanh(out)\n",
    "print(out_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4f1fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995271ec",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba45073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4281,  0.1108]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0000, 0.1108]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.5000, 0.5277]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4621, 0.4836]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_all = out\n",
    "print(out_all)\n",
    "out_all = torch.relu(out_all)\n",
    "print(out_all)\n",
    "out_all = torch.sigmoid(out_all)\n",
    "print(out_all)\n",
    "out_all = torch.tanh(out_all)\n",
    "print(out_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede5dd7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f10146",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ddff2",
   "metadata": {},
   "source": [
    "## MSE Loss (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74e22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4870, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "target = torch.tensor([[0.0, 1.0]])\n",
    "loss = loss_fn(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff45dd",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d32f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2346)\n"
     ]
    }
   ],
   "source": [
    "ce_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "logits = torch.rand(1, 3)  # raw scores (not softmaxed)\n",
    "target_class = torch.tensor([2])  # class index\n",
    "loss = ce_loss_fn(logits, target_class)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fcdc32",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6676ce",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d488309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(4, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d800bd",
   "metadata": {},
   "source": [
    "## Training Loop (Simple Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "650f79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6918522715568542\n",
      "Epoch 1, Loss: 1.0173901319503784\n",
      "Epoch 2, Loss: 0.2578909993171692\n",
      "Epoch 3, Loss: 0.5979954600334167\n",
      "Epoch 4, Loss: 0.6437032222747803\n",
      "Epoch 5, Loss: 0.8829860687255859\n",
      "Epoch 6, Loss: 0.755384087562561\n",
      "Epoch 7, Loss: 0.7139490842819214\n",
      "Epoch 8, Loss: 0.6853145956993103\n",
      "Epoch 9, Loss: 0.20261052250862122\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    for epoch in range(10):\n",
    "        x = torch.rand(1, 4)\n",
    "        target = torch.tensor([[0.0, 1.0]])\n",
    "\n",
    "        out = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074d970",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b92025",
   "metadata": {},
   "source": [
    "# Mini Neural Network Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf8a21",
   "metadata": {},
   "source": [
    "## Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0debc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 8)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7d988",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9db4ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6074\n",
      "Epoch 1, Loss: 0.6466\n",
      "Epoch 2, Loss: 0.5835\n",
      "Epoch 3, Loss: 0.6002\n",
      "Epoch 4, Loss: 0.5081\n",
      "Epoch 5, Loss: 0.4339\n",
      "Epoch 6, Loss: 0.3963\n",
      "Epoch 7, Loss: 0.2702\n",
      "Epoch 8, Loss: 0.2020\n",
      "Epoch 9, Loss: 0.3615\n",
      "Epoch 10, Loss: 0.2909\n",
      "Epoch 11, Loss: 0.2780\n",
      "Epoch 12, Loss: 0.2191\n",
      "Epoch 13, Loss: 0.2434\n",
      "Epoch 14, Loss: 0.2144\n",
      "Epoch 15, Loss: 0.1419\n",
      "Epoch 16, Loss: 0.1861\n",
      "Epoch 17, Loss: 0.1995\n",
      "Epoch 18, Loss: 0.1378\n",
      "Epoch 19, Loss: 0.0839\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "\n",
    "    model = MLP()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        x = torch.rand(10, 4)\n",
    "        target = torch.rand(10, 2)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff106f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67cdd73",
   "metadata": {},
   "source": [
    "# Classification (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd6f6029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.2017\n",
      "Epoch 1, Loss: 1.0505\n",
      "Epoch 2, Loss: 1.0817\n",
      "Epoch 3, Loss: 1.1032\n",
      "Epoch 4, Loss: 1.1096\n",
      "Epoch 5, Loss: 1.1330\n",
      "Epoch 6, Loss: 1.1253\n",
      "Epoch 7, Loss: 1.1287\n",
      "Epoch 8, Loss: 1.0828\n",
      "Epoch 9, Loss: 1.0940\n",
      "Epoch 10, Loss: 1.1991\n",
      "Epoch 11, Loss: 1.1117\n",
      "Epoch 12, Loss: 1.0777\n",
      "Epoch 13, Loss: 1.0492\n",
      "Epoch 14, Loss: 1.1535\n",
      "Epoch 15, Loss: 1.1025\n",
      "Epoch 16, Loss: 1.1236\n",
      "Epoch 17, Loss: 1.0571\n",
      "Epoch 18, Loss: 1.1035\n",
      "Epoch 19, Loss: 1.0740\n"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 8)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.fc2(self.act1(self.fc1(x)))\n",
    "\n",
    "def test():\n",
    "    model = Classifier()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        x = torch.rand(10, 4)\n",
    "        target = torch.randint(0, 3, (10,))  # class labels: 0, 1, 2\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b198cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2293962",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f774118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.1069\n",
      "Epoch 0, Loss: 1.0435\n",
      "Epoch 0, Loss: 1.1790\n",
      "Epoch 0, Loss: 1.0672\n",
      "Epoch 0, Loss: 1.1153\n",
      "Epoch 0, Loss: 1.0186\n",
      "Epoch 0, Loss: 1.2062\n",
      "Epoch 1, Loss: 1.0566\n",
      "Epoch 1, Loss: 1.1233\n",
      "Epoch 1, Loss: 1.0410\n",
      "Epoch 1, Loss: 1.0855\n",
      "Epoch 1, Loss: 1.1008\n",
      "Epoch 1, Loss: 1.0626\n",
      "Epoch 1, Loss: 1.0617\n",
      "Epoch 2, Loss: 1.1012\n",
      "Epoch 2, Loss: 1.0585\n",
      "Epoch 2, Loss: 1.1075\n",
      "Epoch 2, Loss: 1.0811\n",
      "Epoch 2, Loss: 1.0388\n",
      "Epoch 2, Loss: 1.0859\n",
      "Epoch 2, Loss: 1.0341\n",
      "Epoch 3, Loss: 1.0681\n",
      "Epoch 3, Loss: 1.0304\n",
      "Epoch 3, Loss: 1.1523\n",
      "Epoch 3, Loss: 1.0126\n",
      "Epoch 3, Loss: 1.0237\n",
      "Epoch 3, Loss: 1.1301\n",
      "Epoch 3, Loss: 1.1867\n",
      "Epoch 4, Loss: 1.0649\n",
      "Epoch 4, Loss: 1.0430\n",
      "Epoch 4, Loss: 0.9975\n",
      "Epoch 4, Loss: 1.0505\n",
      "Epoch 4, Loss: 1.1943\n",
      "Epoch 4, Loss: 1.0473\n",
      "Epoch 4, Loss: 1.1431\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyDataset(Dataset): # type: ignore\n",
    "    def __init__(self):\n",
    "        self.data = torch.rand(100, 4)  # 100 samples, 4 features\n",
    "        self.labels = torch.randint(0, 3, (100,))  # 3 classes: 0, 1, 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def test():\n",
    "\n",
    "    # Model for 4 input features → 3 class logits\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(4, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 3)\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataset = MyDataset()\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        for x_batch, y_batch in loader:\n",
    "            logits = model(x_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c59da0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3111d1d",
   "metadata": {},
   "source": [
    "# solve MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7d21813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.1725\n",
      "Epoch 1, Loss: 0.1720\n",
      "Epoch 2, Loss: 0.0417\n",
      "Test Accuracy: 96.73%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def test():\n",
    "\n",
    "    # MNIST loaders\n",
    "    transform = transforms.ToTensor()\n",
    "    train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size=64)\n",
    "\n",
    "    # Simple model\n",
    "    model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28 * 28, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(3):\n",
    "        for x, y in train_loader:\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\") # type: ignore\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x)\n",
    "            pred_labels = pred.argmax(dim=1)\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
